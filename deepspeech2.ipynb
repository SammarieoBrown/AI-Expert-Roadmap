{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMkm13WHeuYrFH72c1t/ydb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SammarieoBrown/AI-Expert-Roadmap/blob/main/deepspeech2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuJAIpTEJXms"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from jiwer import wer\n",
        "import os\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "K3G25QA3Ja_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "policy = mixed_precision.Policy(\"mixed_float16\")\n",
        "mixed_precision.set_global_policy(policy)\n"
      ],
      "metadata": {
        "id": "-h3Kxtb6Jbpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "U5DS4knrJkgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "xAmwKu56JmPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_DGFmzEJy28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = 'https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2'\n",
        "data_path = keras.utils.get_file(\"LJSpeech-1.1\", data_url,untar=True)"
      ],
      "metadata": {
        "id": "3kjBYyKpJ-5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wavs_path = data_path + \"/wavs/\"\n",
        "metadata_path = data_path + \"/metadata.csv\""
      ],
      "metadata": {
        "id": "mJe4ENTbKCAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read metadata from file and parse it\n",
        "metadata_df = pd.read_csv(metadata_path,sep=\"|\",header=None, quoting=3)\n",
        "metadata_df.head()"
      ],
      "metadata": {
        "id": "Nt_hE3ZFKEAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Number of samples: {len(metadata_df)}\")"
      ],
      "metadata": {
        "id": "NMfv6xN3KF22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_df.tail()"
      ],
      "metadata": {
        "id": "Z4SdJSw0KHAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_df.columns = ['file_name','transcription','normalized_transcription']\n",
        "metadata_df = metadata_df[['file_name','normalized_transcription']]\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "metadata_df.head()"
      ],
      "metadata": {
        "id": "3dzChRlTKISt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(metadata_df)*0.90)\n",
        "df_train = metadata_df[:split]\n",
        "df_val = metadata_df[split:]\n",
        "\n",
        "print(f\"Number of training samples: {len(df_train)}\")\n",
        "print(f\"Number of validation samples: {len(df_val)}\")"
      ],
      "metadata": {
        "id": "DWN1yXA8KJOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The set of characters accepted in the transcription.\n",
        "characters = [x for x in \"abcdefghijklmnoprstuvwxyz'?! \"]\n",
        "# Mapping characters to integers\n",
        "\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = keras.layers.StringLookup(\n",
        "\n",
        "vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ],
      "metadata": {
        "id": "INjKueVnKLVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# an integer scalar tensor. the window length in samples\n",
        "frame_length = 256\n",
        "# an integer scalar tensor. the number of samples to step\n",
        "frame_step = 160 \n",
        "# a float scalar tensor. the magnitude of the STFT window\n",
        "# if not provided, uses the smallest power of 2 enclosing frame_length\n",
        "fft_length = 384\n"
      ],
      "metadata": {
        "id": "7HZZNuwQKqGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_single_sample(wav_file, label): #encode_single_sample is the original implementation\n",
        "  # Print the file path before reading the file\n",
        "  # 1. read wav file\n",
        "  file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
        "\n",
        "  # 2. decode wav file\n",
        "  audio, _ = tf.audio.decode_wav(file)\n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "  # change type to float32\n",
        "  audio = tf.cast(audio, tf.float32)\n",
        "  # 4. get the spectrogram\n",
        "  spectrogram = tf.signal.stft(\n",
        "      audio,\n",
        "      frame_length=frame_length,\n",
        "      frame_step=frame_step,\n",
        "      fft_length=fft_length,\n",
        "      )\n",
        "  # 5. get the magnitude spectrogram\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "  #6 normalize the spectrogram\n",
        "  means = tf.math.reduce_mean(spectrogram, axis=1, keepdims=True)\n",
        "  stddevs = tf.math.reduce_std(spectrogram, axis=1, keepdims=True)\n",
        "  spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "  # process the label\n",
        "\n",
        "  # 7. convert the label to a tensor\n",
        "  label = tf.strings.lower(label)\n",
        "  label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "  # 8. map the characters to numbers\n",
        "  label = char_to_num(label)\n",
        "  return spectrogram, label\n"
      ],
      "metadata": {
        "id": "cYknS4ymK9lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "# Define the trainig dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"file_name\"]),list(df_train[\"normalized_transcription\"]))\n",
        ")\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Define the validation dataset\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"file_name\"]),list(df_val[\"normalized_transcription\"]))\n",
        ")\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "I00yF3aiLTU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 5))\n",
        "for batch in train_dataset.take(1):\n",
        "  spectrogram = batch[0][0].numpy()\n",
        "  spectrogram = np.array([np.trim_zeros(x) for x in np.transpose(spectrogram)])\n",
        "  label = batch[1][0]\n",
        "  # print(f\"spectrogram  {spectrogram}\")\n",
        "\n",
        "  # print(f\"labels  {label}\")\n",
        "\n",
        "  # plot the spectrogram\n",
        "  label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "  ax = plt.subplot(2, 1, 1)\n",
        "  ax.imshow(spectrogram, aspect=\"auto\", origin=\"lower\")\n",
        "  ax.set_title(label)\n",
        "  ax.axis(\"off\")\n",
        "\n",
        "  # plot the waveform\n",
        "  file = tf.io.read_file(wavs_path + list(df_train[\"file_name\"])[0] + \".wav\")\n",
        "  audio, _ = tf.audio.decode_wav(file, desired_channels=1)\n",
        "  audio = audio.numpy()\n",
        "  ax = plt.subplot(2, 1, 2)\n",
        "  plt.plot(audio)\n",
        "  ax.set_title(\"Waveform\")\n",
        "  ax.set_xlim(0, len(audio))\n",
        "  display.display(display.Audio(np.transpose(audio), rate=18000))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mddkOPEwNGZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "  # compute the ctc loss\n",
        "  batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "  input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "  label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "  input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "  label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "  loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "  return loss\n"
      ],
      "metadata": {
        "id": "FjkQoPnvN94r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
        "  # model input\n",
        "  input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
        "  # Expand the dimension of the spectrogram to use te 2D convolution\n",
        "  x = layers.Reshape((-1, input_dim, 1), name='expand_dim')(input_spectrogram)\n",
        "  # Convolutional layer 1\n",
        "  x = layers.Conv2D(\n",
        "      filters=32,\n",
        "      kernel_size=[11, 41],\n",
        "      strides=[2, 2],\n",
        "      # activation=\"relu\",\n",
        "      # kernel_initializer=\"he_normal\",\n",
        "      padding=\"same\",\n",
        "      use_bias=False,\n",
        "      name=\"conv_1\",\n",
        "  )(x)\n",
        "  x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
        "  x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
        "\n",
        "  # Convolutional layer 2\n",
        "  x = layers.Conv2D(\n",
        "      filters=32,\n",
        "      kernel_size=[11, 21],\n",
        "      strides=[1, 2],\n",
        "      # activation=\"relu\",\n",
        "      # kernel_initializer=\"he_normal\",\n",
        "      padding=\"same\",\n",
        "      use_bias=False,\n",
        "      name=\"conv_2\",\n",
        "  )(x)\n",
        "  x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
        "  x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
        "\n",
        "  # reshape the resulted volume to feed the RNNs layers\n",
        "  x = layers.Reshape((-1, x.shape[-2]*x.shape[-1]))(x)\n",
        "\n",
        "  # RNN layers\n",
        "  for i in range(1,rnn_layers+1):\n",
        "    recurrent = layers.GRU(\n",
        "        units= rnn_units,\n",
        "        activation=\"tanh\",\n",
        "        recurrent_activation=\"sigmoid\",\n",
        "        use_bias=True,\n",
        "        return_sequences=True,\n",
        "        reset_after=True,\n",
        "        # kernel_initializer=\"glorot_uniform\",\n",
        "        name=f\"gru_{i}\",\n",
        "    )\n",
        "    x = layers.Bidirectional(\n",
        "      recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
        "    )(x)\n",
        "    if i < rnn_layers:\n",
        "      x = layers.Dropout(rate = 0.5)(x)\n",
        "  # Dense layer\n",
        "  x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
        "  x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
        "  x = layers.Dropout(rate = 0.5)(x)\n",
        "\n",
        "  # Classfication layer\n",
        "\n",
        "  output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
        "\n",
        "  # define the model\n",
        "\n",
        "  model = keras.models.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
        "\n",
        "  # optimizer\n",
        "  opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "  # compile the model\n",
        "  model.compile(optimizer=opt, loss=CTCLoss)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "Oj407tB2OHyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the model\n",
        "\n",
        "model = build_model(\n",
        "    input_dim=fft_length// 2 + 1,\n",
        "    output_dim= char_to_num.vocabulary_size(),\n",
        "    rnn_layers=5,\n",
        ")\n",
        "model.summary(line_length=110)"
      ],
      "metadata": {
        "id": "1Pxdj5WhOYCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  utils function for the training and evaluation\n",
        "def decode_batch_predictions(pred):\n",
        "  input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "  # use greedy search. For complex tasks, you can use beam search\n",
        "  results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "  # iterate over the results and get back the text\n",
        "  output_text = []\n",
        "  for result in results:\n",
        "    result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "    output_text.append(result)\n",
        "  return output_text"
      ],
      "metadata": {
        "id": "2qeWx5BtOclP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CallbackEval(keras.callbacks.Callback):\n",
        "  def __init__(self, dataset):\n",
        "    super().__init__()\n",
        "    self.dataset = dataset\n",
        "\n",
        "  def on_epoch_end(self, epoch:int, logs=None):\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    for batch in self.dataset:\n",
        "      X, y = batch\n",
        "      batch_predictions = model.predict(X)\n",
        "      batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "      predictions.extend(batch_predictions)\n",
        "      for label in y:\n",
        "        label = (\n",
        "            tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        )\n",
        "        targets.append(label)\n",
        "    wer_score = wer(targets, predictions)\n",
        "    print(\"-\" * 100)\n",
        "    print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "    print(\"-\" * 100)\n",
        "    for i in np.random.randint(0, len(predictions), 2):\n",
        "      print(f\"Target: {targets[i]}\")\n",
        "      print(f\"Prediction: {predictions[i]}\")\n",
        "      print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "ZEF0XUkPOpiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "epochs =2\n",
        "\n",
        "# callback function to check transcription during training\n",
        "\n",
        "validation_callback = CallbackEval(validation_dataset)\n",
        "\n",
        "# train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[validation_callback],\n",
        ") "
      ],
      "metadata": {
        "id": "uV5RG7qkOsDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22BuqyDyOzmJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}